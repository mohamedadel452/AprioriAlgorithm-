{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPt5I8ajIUDo",
        "outputId": "8592c0e2-ee2a-4835-fbb5-e797ff013987"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frequent Itemsets:\n",
            "frozenset({'Y'})\n",
            "frozenset({'E'})\n",
            "frozenset({'O'})\n",
            "frozenset({'K'})\n",
            "frozenset({'M'})\n",
            "frozenset({'K', 'Y'})\n",
            "frozenset({'O', 'E'})\n",
            "frozenset({'K', 'E'})\n",
            "frozenset({'K', 'M'})\n",
            "frozenset({'O', 'K'})\n",
            "frozenset({'O', 'K', 'E'})\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "from itertools import chain\n",
        "import pandas as pd\n",
        "\n",
        "class AprioriAlgorithm:\n",
        "    def __init__(self, data):\n",
        "        self.transactions = [set(transaction) for transaction in data]\n",
        "        self.min_support = 3  # Adjust the minimum support threshold as needed\n",
        "\n",
        "    def get_frequent_items(self):\n",
        "        item_counts = Counter(chain.from_iterable(self.transactions))\n",
        "        frequent_items = {item for item, count in item_counts.items() if count >= self.min_support}\n",
        "        return frequent_items\n",
        "\n",
        "    def generate_candidates(self, prev_frequent_items, length):\n",
        "        candidates = []\n",
        "        for item1 in prev_frequent_items:\n",
        "            for item2 in prev_frequent_items:\n",
        "                if isinstance(item1, str):\n",
        "                    set1 = frozenset([item1])\n",
        "                else:\n",
        "                    set1 = frozenset(item1)\n",
        "\n",
        "                if isinstance(item2, str):\n",
        "                    set2 = frozenset([item2])\n",
        "                else:\n",
        "                    set2 = frozenset(item2)\n",
        "\n",
        "                union_set = set1.union(set2)\n",
        "                if len(union_set) == length and union_set not in candidates:\n",
        "                    candidates.append(union_set)\n",
        "        return candidates\n",
        "\n",
        "    def generate_frequent_itemsets(self):\n",
        "        frequent_itemsets = []\n",
        "        k = 1\n",
        "        prev_frequent_items = self.get_frequent_items()\n",
        "\n",
        "        while prev_frequent_items:\n",
        "            frequent_itemsets.extend(prev_frequent_items)\n",
        "            k += 1\n",
        "            candidates = self.generate_candidates(prev_frequent_items, k)\n",
        "            candidate_counts = Counter()\n",
        "\n",
        "            for transaction in self.transactions:\n",
        "                for candidate in candidates:\n",
        "                    if candidate.issubset(transaction):\n",
        "                        candidate_counts[candidate] += 1\n",
        "\n",
        "            prev_frequent_items = {itemset for itemset, count in candidate_counts.items() if count >= self.min_support}\n",
        "\n",
        "        return frequent_itemsets\n",
        "\n",
        "def convert_excel(input_file, output_file):\n",
        "    # Read the Excel file\n",
        "    df = pd.read_excel(input_file)\n",
        "\n",
        "    # Check if the DataFrame is already in horizontal format\n",
        "    if 'TiD' in df.columns and 'items' in df.columns:\n",
        "        return df\n",
        "\n",
        "    # Create a dictionary to store TiD_items and corresponding items\n",
        "    tid_dict = {}\n",
        "\n",
        "    # Determine column names based on availability\n",
        "    tid_column = 'TiD' if 'TiD' in df.columns else 'TiD_items'\n",
        "    items_column = 'items'\n",
        "\n",
        "    # Iterate through rows in the DataFrame\n",
        "    for index, row in df.iterrows():\n",
        "        tid_items = str(row[tid_column]).split(',')  # Convert to string before splitting\n",
        "        items = list(row[items_column])\n",
        "\n",
        "        # Iterate through TiD_items and items\n",
        "        for tid in tid_items:\n",
        "            if tid in tid_dict:\n",
        "                tid_dict[tid] += items\n",
        "            else:\n",
        "                tid_dict[tid] = items.copy()\n",
        "\n",
        "    # Create a new DataFrame for the output\n",
        "    output_df = pd.DataFrame(list(tid_dict.items()), columns=[tid_column, items_column])\n",
        "\n",
        "    # Combine items into strings\n",
        "    output_df[items_column] = output_df[items_column].apply(lambda x: ','.join(set(x)))\n",
        "\n",
        "    # Write the result to a new Excel file\n",
        "    output_df.to_excel(output_file, index=False)\n",
        "\n",
        "    return output_df  # Return the modified DataFrame\n",
        "\n",
        "# Example usage:\n",
        "input_file = '/content/sample_data/Horizontal_Format (1) (1).xlsx'\n",
        "output_file = 'output_file.xlsx'\n",
        "modified_data = convert_excel(input_file, output_file)\n",
        "\n",
        "# Example usage with modified data\n",
        "apriori = AprioriAlgorithm(modified_data['items'].apply(lambda x: x.split(',')).tolist())\n",
        "frequent_itemsets = apriori.generate_frequent_itemsets()\n",
        "\n",
        "print(\"Frequent Itemsets:\")\n",
        "for itemset in frequent_itemsets:\n",
        "    print(frozenset(itemset))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from itertools import chain\n",
        "import pandas as pd\n",
        "\n",
        "class AprioriAlgorithm:\n",
        "    def __init__(self, data):\n",
        "        self.transactions = [set(transaction) for transaction in data]\n",
        "        self.min_support = 3  # Adjust the minimum support threshold as needed\n",
        "\n",
        "    def get_frequent_items(self):\n",
        "        item_counts = Counter(chain.from_iterable(self.transactions))\n",
        "        frequent_items = {item for item, count in item_counts.items() if count >= self.min_support}\n",
        "        return frequent_items\n",
        "\n",
        "    def generate_candidates(self, prev_frequent_items, length):\n",
        "        candidates = []\n",
        "        for item1 in prev_frequent_items:\n",
        "            for item2 in prev_frequent_items:\n",
        "                if isinstance(item1, str):\n",
        "                    set1 = frozenset([item1])\n",
        "                else:\n",
        "                    set1 = frozenset(item1)\n",
        "\n",
        "                if isinstance(item2, str):\n",
        "                    set2 = frozenset([item2])\n",
        "                else:\n",
        "                    set2 = frozenset(item2)\n",
        "\n",
        "                union_set = set1.union(set2)\n",
        "                if len(union_set) == length and union_set not in candidates:\n",
        "                    candidates.append(union_set)\n",
        "        return candidates\n",
        "\n",
        "    def generate_frequent_itemsets(self):\n",
        "        frequent_itemsets = []\n",
        "        k = 1\n",
        "        prev_frequent_items = self.get_frequent_items()\n",
        "\n",
        "        while prev_frequent_items:\n",
        "            frequent_itemsets.extend(prev_frequent_items)\n",
        "            k += 1\n",
        "            candidates = self.generate_candidates(prev_frequent_items, k)\n",
        "            candidate_counts = Counter()\n",
        "\n",
        "            for transaction in self.transactions:\n",
        "                for candidate in candidates:\n",
        "                    if candidate.issubset(transaction):\n",
        "                        candidate_counts[candidate] += 1\n",
        "\n",
        "            prev_frequent_items = {itemset for itemset, count in candidate_counts.items() if count >= self.min_support}\n",
        "\n",
        "        return frequent_itemsets\n",
        "\n",
        "def convert_excel(input_file, output_file):\n",
        "    # Read the Excel file\n",
        "    df = pd.read_excel(input_file)\n",
        "\n",
        "    # Check if the DataFrame is already in horizontal format\n",
        "    if 'TiD' in df.columns and 'items' in df.columns:\n",
        "        return df\n",
        "\n",
        "    # Create a dictionary to store TiD_items and corresponding items\n",
        "    tid_dict = {}\n",
        "\n",
        "    # Determine column names based on availability\n",
        "    tid_column = 'TiD' if 'TiD' in df.columns else 'TiD_items'\n",
        "    items_column = 'items'\n",
        "\n",
        "    # Iterate through rows in the DataFrame\n",
        "    for index, row in df.iterrows():\n",
        "        tid_items = str(row[tid_column]).split(',')  # Convert to string before splitting\n",
        "        items = list(row[items_column])\n",
        "\n",
        "        # Iterate through TiD_items and items\n",
        "        for tid in tid_items:\n",
        "            if tid in tid_dict:\n",
        "                tid_dict[tid] += items\n",
        "            else:\n",
        "                tid_dict[tid] = items.copy()\n",
        "\n",
        "    # Create a new DataFrame for the output\n",
        "    output_df = pd.DataFrame(list(tid_dict.items()), columns=[tid_column, items_column])\n",
        "\n",
        "    # Combine items into strings\n",
        "    output_df[items_column] = output_df[items_column].apply(lambda x: ','.join(set(x)))\n",
        "\n",
        "    # Write the result to a new Excel file\n",
        "    output_df.to_excel(output_file, index=False)\n",
        "\n",
        "    return output_df  # Return the modified DataFrame\n",
        "\n",
        "# Example usage:\n",
        "input_file = '/content/sample_data/Horizontal_Format.xlsx'\n",
        "output_file = 'output_file.xlsx'\n",
        "modified_data = convert_excel(input_file, output_file)\n",
        "\n",
        "# Example usage with modified data\n",
        "apriori = AprioriAlgorithm(modified_data['items'].apply(lambda x: x.split(',')).tolist())\n",
        "frequent_itemsets = apriori.generate_frequent_itemsets()\n",
        "\n",
        "print(\"Frequent Itemsets:\")\n",
        "for itemset in frequent_itemsets:\n",
        "    print(set(itemset))  # Convert frozenset to set before printing\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDcobkr_Mjqi",
        "outputId": "7ed4bfb3-4d50-4fda-924e-358248a977e3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frequent Itemsets:\n",
            "{'k'}\n",
            "{'o'}\n",
            "{'y'}\n",
            "{'e'}\n",
            "{'m'}\n",
            "{'k', 'y'}\n",
            "{'k', 'e'}\n",
            "{'o', 'e'}\n",
            "{'k', 'o'}\n",
            "{'k', 'm'}\n",
            "{'k', 'e', 'o'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from itertools import chain, combinations\n",
        "import pandas as pd\n",
        "\n",
        "class AprioriAlgorithm:\n",
        "    def __init__(self, data, min_support=3, min_confidence=0.5):\n",
        "        self.transactions = [set(transaction) if isinstance(transaction, (set, frozenset)) else set(transaction.split(',')) for transaction in data]\n",
        "        self.min_support = min_support\n",
        "        self.min_confidence = min_confidence\n",
        "        self.frequent_itemsets = self.generate_frequent_itemsets()\n",
        "\n",
        "    def get_frequent_items(self):\n",
        "        item_counts = Counter(chain.from_iterable(self.transactions))\n",
        "        frequent_items = {item for item, count in item_counts.items() if count >= self.min_support}\n",
        "        return frequent_items\n",
        "\n",
        "    def generate_candidates(self, prev_frequent_items, length):\n",
        "        candidates = []\n",
        "        for item1 in prev_frequent_items:\n",
        "            for item2 in prev_frequent_items:\n",
        "                if isinstance(item1, str):\n",
        "                    set1 = frozenset([item1])\n",
        "                else:\n",
        "                    set1 = frozenset(item1)\n",
        "\n",
        "                if isinstance(item2, str):\n",
        "                    set2 = frozenset([item2])\n",
        "                else:\n",
        "                    set2 = frozenset(item2)\n",
        "\n",
        "                union_set = set1.union(set2)\n",
        "                if len(union_set) == length and union_set not in candidates:\n",
        "                    candidates.append(union_set)\n",
        "        return candidates\n",
        "\n",
        "    def generate_frequent_itemsets(self):\n",
        "        frequent_itemsets = []\n",
        "        k = 1\n",
        "        prev_frequent_items = self.get_frequent_items()\n",
        "\n",
        "        while prev_frequent_items:\n",
        "            frequent_itemsets.extend(prev_frequent_items)\n",
        "            k += 1\n",
        "            candidates = self.generate_candidates(prev_frequent_items, k)\n",
        "            candidate_counts = Counter()\n",
        "\n",
        "            for transaction in self.transactions:\n",
        "                for candidate in candidates:\n",
        "                    if candidate.issubset(transaction):\n",
        "                        candidate_counts[candidate] += 1\n",
        "\n",
        "            prev_frequent_items = {itemset for itemset, count in candidate_counts.items() if count >= self.min_support}\n",
        "\n",
        "        return frequent_itemsets\n",
        "\n",
        "    def calculate_support(self, itemset):\n",
        "        count = sum(1 for transaction in self.transactions if itemset.issubset(transaction))\n",
        "        return count\n",
        "\n",
        "    def calculate_confidence(self, antecedent, consequent):\n",
        "        antecedent_support = self.calculate_support(antecedent)\n",
        "        rule_support = self.calculate_support(antecedent.union(consequent))\n",
        "\n",
        "        if antecedent_support == 0:\n",
        "            return 0  # Avoid division by zero\n",
        "\n",
        "        confidence = rule_support / antecedent_support\n",
        "        return confidence\n",
        "\n",
        "    def calculate_lift(self, rule):\n",
        "        antecedent, consequent = rule\n",
        "        antecedent_support = self.calculate_support(antecedent)\n",
        "        consequent_support = self.calculate_support(consequent)\n",
        "        rule_support = self.calculate_support(antecedent.union(consequent))\n",
        "\n",
        "        if rule_support == 0:\n",
        "            return 0  # Avoid division by zero\n",
        "\n",
        "        lift = (len(self.transactions) * rule_support) / (antecedent_support * consequent_support)\n",
        "        return lift\n",
        "\n",
        "    def generate_association_rules(self):\n",
        "        rules = []\n",
        "        for itemset in self.frequent_itemsets:\n",
        "            if len(itemset) > 1:\n",
        "                for antecedent_size in range(1, len(itemset)):\n",
        "                    antecedents = set(combinations(itemset, antecedent_size))\n",
        "                    for antecedent in antecedents:\n",
        "                        antecedent = set(antecedent)\n",
        "                        consequent = itemset - antecedent\n",
        "\n",
        "                        confidence = self.calculate_confidence(antecedent, itemset)\n",
        "                        if confidence >= self.min_confidence:\n",
        "                            lift = self.calculate_lift((antecedent, consequent))\n",
        "                            rules.append((antecedent, consequent, confidence, lift))\n",
        "\n",
        "        return rules\n",
        "\n",
        "# Example usage:\n",
        "input_file = '/content/sample_data/Horizontal_Format.xlsx'\n",
        "output_file = 'output_file.xlsx'\n",
        "modified_data = convert_excel(input_file, output_file)\n",
        "\n",
        "# Instantiate AprioriAlgorithm with modified data\n",
        "apriori = AprioriAlgorithm(modified_data['items'].tolist())\n",
        "\n",
        "# Print Frequent Itemsets\n",
        "print(\"Frequent Itemsets:\")\n",
        "for itemset in apriori.frequent_itemsets:\n",
        "    print(set(itemset))  # Convert frozenset to set before printing\n",
        "\n",
        "# Generate and Print Association Rules\n",
        "association_rules = apriori.generate_association_rules()\n",
        "print(\"\\nAssociation Rules:\")\n",
        "for rule in association_rules:\n",
        "    antecedent, consequent, confidence, lift = rule\n",
        "    print(f\"{set(antecedent)} -> {set(consequent)} (Confidence: {confidence:.2f}, Lift: {lift:.2f})\")\n"
      ],
      "metadata": {
        "id": "nNU0QZSzp3D4",
        "outputId": "e98abaa9-fe6a-40bb-90aa-92ec10478129",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frequent Itemsets:\n",
            "{'k'}\n",
            "{'o'}\n",
            "{'y'}\n",
            "{'e'}\n",
            "{'m'}\n",
            "{'k', 'y'}\n",
            "{'k', 'e'}\n",
            "{'o', 'e'}\n",
            "{'k', 'o'}\n",
            "{'k', 'm'}\n",
            "{'k', 'e', 'o'}\n",
            "\n",
            "Association Rules:\n",
            "{'y'} -> {'k'} (Confidence: 1.00, Lift: 1.00)\n",
            "{'k'} -> {'y'} (Confidence: 0.60, Lift: 1.00)\n",
            "{'e'} -> {'k'} (Confidence: 1.00, Lift: 1.00)\n",
            "{'k'} -> {'e'} (Confidence: 0.80, Lift: 1.00)\n",
            "{'o'} -> {'e'} (Confidence: 1.00, Lift: 1.25)\n",
            "{'e'} -> {'o'} (Confidence: 0.75, Lift: 1.25)\n",
            "{'o'} -> {'k'} (Confidence: 1.00, Lift: 1.00)\n",
            "{'k'} -> {'o'} (Confidence: 0.60, Lift: 1.00)\n",
            "{'m'} -> {'k'} (Confidence: 1.00, Lift: 1.00)\n",
            "{'k'} -> {'m'} (Confidence: 0.60, Lift: 1.00)\n",
            "{'o'} -> {'k', 'e'} (Confidence: 1.00, Lift: 1.25)\n",
            "{'e'} -> {'k', 'o'} (Confidence: 0.75, Lift: 1.25)\n",
            "{'k'} -> {'e', 'o'} (Confidence: 0.60, Lift: 1.00)\n",
            "{'e', 'o'} -> {'k'} (Confidence: 1.00, Lift: 1.00)\n",
            "{'k', 'o'} -> {'e'} (Confidence: 1.00, Lift: 1.25)\n",
            "{'k', 'e'} -> {'o'} (Confidence: 0.75, Lift: 1.25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from itertools import chain, combinations\n",
        "import pandas as pd\n",
        "\n",
        "class AprioriAlgorithm:\n",
        "    def __init__(self, data, min_support=3, min_confidence=0.5):\n",
        "        self.transactions = [set(transaction) if isinstance(transaction, (set, frozenset)) else set(transaction.split(',')) for transaction in data]\n",
        "        self.min_support = min_support\n",
        "        self.min_confidence = min_confidence\n",
        "        self.frequent_itemsets = self.generate_frequent_itemsets()\n",
        "\n",
        "    def get_frequent_items(self):\n",
        "        item_counts = Counter(chain.from_iterable(self.transactions))\n",
        "        frequent_items = {item for item, count in item_counts.items() if count >= self.min_support}\n",
        "        return frequent_items\n",
        "\n",
        "    def generate_candidates(self, prev_frequent_items, length):\n",
        "        candidates = []\n",
        "        for item1 in prev_frequent_items:\n",
        "            for item2 in prev_frequent_items:\n",
        "                if isinstance(item1, str):\n",
        "                    set1 = frozenset([item1])\n",
        "                else:\n",
        "                    set1 = frozenset(item1)\n",
        "\n",
        "                if isinstance(item2, str):\n",
        "                    set2 = frozenset([item2])\n",
        "                else:\n",
        "                    set2 = frozenset(item2)\n",
        "\n",
        "                union_set = set1.union(set2)\n",
        "                if len(union_set) == length and union_set not in candidates:\n",
        "                    candidates.append(union_set)\n",
        "        return candidates\n",
        "\n",
        "    def generate_frequent_itemsets(self):\n",
        "        frequent_itemsets = []\n",
        "        k = 1\n",
        "        prev_frequent_items = self.get_frequent_items()\n",
        "\n",
        "        while prev_frequent_items:\n",
        "            frequent_itemsets.extend(prev_frequent_items)\n",
        "            k += 1\n",
        "            candidates = self.generate_candidates(prev_frequent_items, k)\n",
        "            candidate_counts = Counter()\n",
        "\n",
        "            for transaction in self.transactions:\n",
        "                for candidate in candidates:\n",
        "                    if candidate.issubset(transaction):\n",
        "                        candidate_counts[candidate] += 1\n",
        "\n",
        "            prev_frequent_items = {itemset for itemset, count in candidate_counts.items() if count >= self.min_support}\n",
        "\n",
        "        return frequent_itemsets\n",
        "\n",
        "    def calculate_support(self, itemset):\n",
        "        count = sum(1 for transaction in self.transactions if itemset.issubset(transaction))\n",
        "        return count\n",
        "\n",
        "    def calculate_confidence(self, antecedent, consequent):\n",
        "        antecedent_support = self.calculate_support(antecedent)\n",
        "        rule_support = self.calculate_support(antecedent.union(consequent))\n",
        "\n",
        "        if antecedent_support == 0:\n",
        "            return 0, None  # Avoid division by zero\n",
        "\n",
        "        confidence = rule_support / antecedent_support\n",
        "        return confidence, \"Positive\" if confidence >= 0 else \"Negative\"\n",
        "\n",
        "    def calculate_lift(self, rule):\n",
        "        antecedent, consequent = rule\n",
        "        antecedent_support = self.calculate_support(antecedent)\n",
        "        consequent_support = self.calculate_support(consequent)\n",
        "        rule_support = self.calculate_support(antecedent.union(consequent))\n",
        "\n",
        "        if rule_support == 0:\n",
        "            return 0, None  # Avoid division by zero\n",
        "\n",
        "        lift = (len(self.transactions) * rule_support) / (antecedent_support * consequent_support)\n",
        "        return lift, \"Positive\" if lift >= 1 else \"Negative\"\n",
        "\n",
        "    def generate_association_rules(self):\n",
        "        rules = []\n",
        "        for itemset in self.frequent_itemsets:\n",
        "            if len(itemset) > 1:\n",
        "                for antecedent_size in range(1, len(itemset)):\n",
        "                    antecedents = set(combinations(itemset, antecedent_size))\n",
        "                    for antecedent in antecedents:\n",
        "                        antecedent = set(antecedent)\n",
        "                        consequent = itemset - antecedent\n",
        "\n",
        "                        confidence, confidence_direction = self.calculate_confidence(antecedent, itemset)\n",
        "                        lift, lift_direction = self.calculate_lift((antecedent, consequent))\n",
        "\n",
        "                        rules.append((antecedent, consequent, confidence, confidence_direction, lift, lift_direction))\n",
        "\n",
        "        return rules\n",
        "\n",
        "# Example usage:\n",
        "input_file = '/content/sample_data/Horizontal_Format.xlsx'\n",
        "output_file = 'output_file.xlsx'\n",
        "modified_data = convert_excel(input_file, output_file)\n",
        "\n",
        "# Instantiate AprioriAlgorithm with modified data\n",
        "apriori = AprioriAlgorithm(modified_data['items'].tolist())\n",
        "\n",
        "# Print Frequent Itemsets\n",
        "print(\"Frequent Itemsets:\")\n",
        "for itemset in apriori.frequent_itemsets:\n",
        "    print(set(itemset))  # Convert frozenset to set before printing\n",
        "\n",
        "# Generate and Print Association Rules\n",
        "association_rules = apriori.generate_association_rules()\n",
        "print(\"\\nAssociation Rules:\")\n",
        "for rule in association_rules:\n",
        "    antecedent, consequent, confidence, confidence_direction, lift, lift_direction = rule\n",
        "    print(f\"{set(antecedent)} -> {set(consequent)} (Confidence: {confidence:.2f} ({confidence_direction}), Lift: {lift:.2f} ({lift_direction}))\")\n"
      ],
      "metadata": {
        "id": "H-PIgDmxq15V",
        "outputId": "c4c360c8-0519-4645-bb8c-91f54d9de07b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frequent Itemsets:\n",
            "{'k'}\n",
            "{'o'}\n",
            "{'y'}\n",
            "{'e'}\n",
            "{'m'}\n",
            "{'k', 'y'}\n",
            "{'k', 'e'}\n",
            "{'o', 'e'}\n",
            "{'k', 'o'}\n",
            "{'k', 'm'}\n",
            "{'k', 'e', 'o'}\n",
            "\n",
            "Association Rules:\n",
            "{'y'} -> {'k'} (Confidence: 1.00 (Positive), Lift: 1.00 (Positive))\n",
            "{'k'} -> {'y'} (Confidence: 0.60 (Positive), Lift: 1.00 (Positive))\n",
            "{'e'} -> {'k'} (Confidence: 1.00 (Positive), Lift: 1.00 (Positive))\n",
            "{'k'} -> {'e'} (Confidence: 0.80 (Positive), Lift: 1.00 (Positive))\n",
            "{'o'} -> {'e'} (Confidence: 1.00 (Positive), Lift: 1.25 (Positive))\n",
            "{'e'} -> {'o'} (Confidence: 0.75 (Positive), Lift: 1.25 (Positive))\n",
            "{'o'} -> {'k'} (Confidence: 1.00 (Positive), Lift: 1.00 (Positive))\n",
            "{'k'} -> {'o'} (Confidence: 0.60 (Positive), Lift: 1.00 (Positive))\n",
            "{'m'} -> {'k'} (Confidence: 1.00 (Positive), Lift: 1.00 (Positive))\n",
            "{'k'} -> {'m'} (Confidence: 0.60 (Positive), Lift: 1.00 (Positive))\n",
            "{'o'} -> {'k', 'e'} (Confidence: 1.00 (Positive), Lift: 1.25 (Positive))\n",
            "{'e'} -> {'k', 'o'} (Confidence: 0.75 (Positive), Lift: 1.25 (Positive))\n",
            "{'k'} -> {'e', 'o'} (Confidence: 0.60 (Positive), Lift: 1.00 (Positive))\n",
            "{'e', 'o'} -> {'k'} (Confidence: 1.00 (Positive), Lift: 1.00 (Positive))\n",
            "{'k', 'o'} -> {'e'} (Confidence: 1.00 (Positive), Lift: 1.25 (Positive))\n",
            "{'k', 'e'} -> {'o'} (Confidence: 0.75 (Positive), Lift: 1.25 (Positive))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from itertools import chain, combinations\n",
        "import pandas as pd\n",
        "\n",
        "class AprioriAlgorithm:\n",
        "    def __init__(self, data, min_support=3, min_confidence=0.5):\n",
        "        self.transactions = [set(transaction) if isinstance(transaction, (set, frozenset)) else set(transaction.split(',')) for transaction in data]\n",
        "        self.min_support = min_support\n",
        "        self.min_confidence = min_confidence\n",
        "        self.frequent_itemsets = self.generate_frequent_itemsets()\n",
        "\n",
        "    def get_frequent_items(self):\n",
        "        item_counts = Counter(chain.from_iterable(self.transactions))\n",
        "        frequent_items = {item for item, count in item_counts.items() if count >= self.min_support}\n",
        "        return frequent_items\n",
        "\n",
        "    def generate_candidates(self, prev_frequent_items, length):\n",
        "        candidates = []\n",
        "        for item1 in prev_frequent_items:\n",
        "            for item2 in prev_frequent_items:\n",
        "                if isinstance(item1, str):\n",
        "                    set1 = frozenset([item1])\n",
        "                else:\n",
        "                    set1 = frozenset(item1)\n",
        "\n",
        "                if isinstance(item2, str):\n",
        "                    set2 = frozenset([item2])\n",
        "                else:\n",
        "                    set2 = frozenset(item2)\n",
        "\n",
        "                union_set = set1.union(set2)\n",
        "                if len(union_set) == length and union_set not in candidates:\n",
        "                    candidates.append(union_set)\n",
        "        return candidates\n",
        "\n",
        "    def generate_frequent_itemsets(self):\n",
        "        frequent_itemsets = []\n",
        "        k = 1\n",
        "        prev_frequent_items = self.get_frequent_items()\n",
        "\n",
        "        while prev_frequent_items:\n",
        "            frequent_itemsets.extend(prev_frequent_items)\n",
        "            k += 1\n",
        "            candidates = self.generate_candidates(prev_frequent_items, k)\n",
        "            candidate_counts = Counter()\n",
        "\n",
        "            for transaction in self.transactions:\n",
        "                for candidate in candidates:\n",
        "                    if candidate.issubset(transaction):\n",
        "                        candidate_counts[candidate] += 1\n",
        "\n",
        "            prev_frequent_items = {itemset for itemset, count in candidate_counts.items() if count >= self.min_support}\n",
        "\n",
        "        return frequent_itemsets\n",
        "\n",
        "    def calculate_support(self, itemset):\n",
        "        count = sum(1 for transaction in self.transactions if itemset.issubset(transaction))\n",
        "        return count\n",
        "\n",
        "    def calculate_confidence(self, antecedent, consequent):\n",
        "        antecedent_support = self.calculate_support(antecedent)\n",
        "        rule_support = self.calculate_support(antecedent.union(consequent))\n",
        "\n",
        "        if antecedent_support == 0:\n",
        "            return 0, None  # Avoid division by zero\n",
        "\n",
        "        confidence = rule_support / antecedent_support\n",
        "        return confidence, \"Positive\" if confidence >= 0 else \"Negative\"\n",
        "\n",
        "    def calculate_lift(self, rule):\n",
        "        antecedent, consequent = rule\n",
        "        antecedent_support = self.calculate_support(antecedent)\n",
        "        consequent_support = self.calculate_support(consequent)\n",
        "        rule_support = self.calculate_support(antecedent.union(consequent))\n",
        "\n",
        "        if rule_support == 0:\n",
        "            return 0, None  # Avoid division by zero\n",
        "\n",
        "        lift = (len(self.transactions) * rule_support) / (antecedent_support * consequent_support)\n",
        "        return lift, \"Positive\" if lift >= 1 else \"Negative\"\n",
        "\n",
        "    def determine_dependency(self, confidence_direction, lift_direction):\n",
        "        if confidence_direction == \"Positive\" and lift_direction == \"Positive\":\n",
        "            return \"Dependent\"\n",
        "        elif confidence_direction == \"Negative\" and lift_direction == \"Negative\":\n",
        "            return \"Dependent\"\n",
        "        elif confidence_direction == \"Positive\" and lift_direction == \"Negative\":\n",
        "            return \"Independent\"\n",
        "        elif confidence_direction == \"Negative\" and lift_direction == \"Positive\":\n",
        "            return \"Independent\"\n",
        "        else:\n",
        "            return \"No Correlation\"\n",
        "\n",
        "    def generate_association_rules(self):\n",
        "        rules = []\n",
        "        for itemset in self.frequent_itemsets:\n",
        "            if len(itemset) > 1:\n",
        "                for antecedent_size in range(1, len(itemset)):\n",
        "                    antecedents = set(combinations(itemset, antecedent_size))\n",
        "                    for antecedent in antecedents:\n",
        "                        antecedent = set(antecedent)\n",
        "                        consequent = itemset - antecedent\n",
        "\n",
        "                        confidence, confidence_direction = self.calculate_confidence(antecedent, itemset)\n",
        "                        lift, lift_direction = self.calculate_lift((antecedent, consequent))\n",
        "                        dependency = self.determine_dependency(confidence_direction, lift_direction)\n",
        "\n",
        "                        rules.append((antecedent, consequent, confidence, confidence_direction, lift, lift_direction, dependency))\n",
        "\n",
        "        return rules\n",
        "\n",
        "# Example usage:\n",
        "input_file = '/content/sample_data/Horizontal_Format.xlsx'\n",
        "output_file = 'output_file.xlsx'\n",
        "modified_data = convert_excel(input_file, output_file)\n",
        "\n",
        "# Instantiate AprioriAlgorithm with modified data\n",
        "apriori = AprioriAlgorithm(modified_data['items'].tolist())\n",
        "\n",
        "# Print Frequent Itemsets\n",
        "print(\"Frequent Itemsets:\")\n",
        "for itemset in apriori.frequent_itemsets:\n",
        "    print(set(itemset))  # Convert frozenset to set before printing\n",
        "\n",
        "# Generate and Print Association Rules\n",
        "association_rules = apriori.generate_association_rules()\n",
        "print(\"\\nAssociation Rules:\")\n",
        "for rule in association_rules:\n",
        "    antecedent, consequent, confidence, confidence_direction, lift, lift_direction, dependency = rule\n",
        "    print(f\"{set(antecedent)} -> {set(consequent)} (Confidence: {confidence:.2f} ({confidence_direction}), Lift: {lift:.2f} ({lift_direction}), Dependency: {dependency})\")\n"
      ],
      "metadata": {
        "id": "RwA3svBqrxdV",
        "outputId": "b9d64ecb-b28a-44ca-9ff4-8001c0d1bdcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frequent Itemsets:\n",
            "{'k'}\n",
            "{'o'}\n",
            "{'y'}\n",
            "{'e'}\n",
            "{'m'}\n",
            "{'k', 'y'}\n",
            "{'k', 'e'}\n",
            "{'o', 'e'}\n",
            "{'k', 'o'}\n",
            "{'k', 'm'}\n",
            "{'k', 'e', 'o'}\n",
            "\n",
            "Association Rules:\n",
            "{'y'} -> {'k'} (Confidence: 1.00 (Positive), Lift: 1.00 (Positive), Dependency: Dependent)\n",
            "{'k'} -> {'y'} (Confidence: 0.60 (Positive), Lift: 1.00 (Positive), Dependency: Dependent)\n",
            "{'e'} -> {'k'} (Confidence: 1.00 (Positive), Lift: 1.00 (Positive), Dependency: Dependent)\n",
            "{'k'} -> {'e'} (Confidence: 0.80 (Positive), Lift: 1.00 (Positive), Dependency: Dependent)\n",
            "{'o'} -> {'e'} (Confidence: 1.00 (Positive), Lift: 1.25 (Positive), Dependency: Dependent)\n",
            "{'e'} -> {'o'} (Confidence: 0.75 (Positive), Lift: 1.25 (Positive), Dependency: Dependent)\n",
            "{'o'} -> {'k'} (Confidence: 1.00 (Positive), Lift: 1.00 (Positive), Dependency: Dependent)\n",
            "{'k'} -> {'o'} (Confidence: 0.60 (Positive), Lift: 1.00 (Positive), Dependency: Dependent)\n",
            "{'m'} -> {'k'} (Confidence: 1.00 (Positive), Lift: 1.00 (Positive), Dependency: Dependent)\n",
            "{'k'} -> {'m'} (Confidence: 0.60 (Positive), Lift: 1.00 (Positive), Dependency: Dependent)\n",
            "{'o'} -> {'k', 'e'} (Confidence: 1.00 (Positive), Lift: 1.25 (Positive), Dependency: Dependent)\n",
            "{'e'} -> {'k', 'o'} (Confidence: 0.75 (Positive), Lift: 1.25 (Positive), Dependency: Dependent)\n",
            "{'k'} -> {'e', 'o'} (Confidence: 0.60 (Positive), Lift: 1.00 (Positive), Dependency: Dependent)\n",
            "{'e', 'o'} -> {'k'} (Confidence: 1.00 (Positive), Lift: 1.00 (Positive), Dependency: Dependent)\n",
            "{'k', 'o'} -> {'e'} (Confidence: 1.00 (Positive), Lift: 1.25 (Positive), Dependency: Dependent)\n",
            "{'k', 'e'} -> {'o'} (Confidence: 0.75 (Positive), Lift: 1.25 (Positive), Dependency: Dependent)\n"
          ]
        }
      ]
    }
  ]
}